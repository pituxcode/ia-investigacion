<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Fundamentos – IA para Investigación Académica</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./modulo-1.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-bf8030b5a8b8f2de5bceddfb8bf38a1d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No se han encontrado resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./fundamentos.html"><span class="chapter-title">Fundamentos</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">IA para Investigación Académica</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bienvenida</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fundamentos.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Fundamentos</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modulo-1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Módulo 1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modulo-2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Módulo 2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./recursos.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Recursos</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#tres-ideas-fuerza" id="toc-tres-ideas-fuerza" class="nav-link active" data-scroll-target="#tres-ideas-fuerza">Tres ideas fuerza</a>
  <ul>
  <li><a href="#un-llm-predice-la-siguiente-palabra" id="toc-un-llm-predice-la-siguiente-palabra" class="nav-link" data-scroll-target="#un-llm-predice-la-siguiente-palabra">Un LLM predice la siguiente palabra</a>
  <ul class="collapse">
  <li><a href="#ia-generativa-más-que-texto" id="toc-ia-generativa-más-que-texto" class="nav-link" data-scroll-target="#ia-generativa-más-que-texto">IA generativa: más que texto</a></li>
  <li><a href="#dos-formas-de-usar-un-modelo" id="toc-dos-formas-de-usar-un-modelo" class="nav-link" data-scroll-target="#dos-formas-de-usar-un-modelo">Dos formas de usar un modelo</a></li>
  <li><a href="#la-arquitectura-transformer" id="toc-la-arquitectura-transformer" class="nav-link" data-scroll-target="#la-arquitectura-transformer">La arquitectura transformer</a></li>
  <li><a href="#de-la-arquitectura-a-la-predicción" id="toc-de-la-arquitectura-a-la-predicción" class="nav-link" data-scroll-target="#de-la-arquitectura-a-la-predicción">De la arquitectura a la predicción</a></li>
  </ul></li>
  <li><a href="#por-eso-alucina" id="toc-por-eso-alucina" class="nav-link" data-scroll-target="#por-eso-alucina">Por eso alucina</a>
  <ul class="collapse">
  <li><a href="#por-qué-las-alucinaciones-son-inevitables" id="toc-por-qué-las-alucinaciones-son-inevitables" class="nav-link" data-scroll-target="#por-qué-las-alucinaciones-son-inevitables">Por qué las alucinaciones son inevitables</a></li>
  </ul></li>
  <li><a href="#dos-técnicas-para-trabajar-con-ia" id="toc-dos-técnicas-para-trabajar-con-ia" class="nav-link" data-scroll-target="#dos-técnicas-para-trabajar-con-ia">Dos técnicas para trabajar con IA</a>
  <ul class="collapse">
  <li><a href="#iterative-prompting-diálogo-iterativo" id="toc-iterative-prompting-diálogo-iterativo" class="nav-link" data-scroll-target="#iterative-prompting-diálogo-iterativo">Iterative prompting (diálogo iterativo)</a></li>
  <li><a href="#meta-prompting" id="toc-meta-prompting" class="nav-link" data-scroll-target="#meta-prompting">Meta prompting</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#profundización-teórica" id="toc-profundización-teórica" class="nav-link" data-scroll-target="#profundización-teórica">Profundización teórica</a>
  <ul>
  <li><a href="#cómo-aprenden-los-llm" id="toc-cómo-aprenden-los-llm" class="nav-link" data-scroll-target="#cómo-aprenden-los-llm">Cómo aprenden los LLM</a>
  <ul class="collapse">
  <li><a href="#fase-1-pre-entrenamiento" id="toc-fase-1-pre-entrenamiento" class="nav-link" data-scroll-target="#fase-1-pre-entrenamiento">Fase 1: Pre-entrenamiento</a></li>
  <li><a href="#fase-2-ajuste-fino-fine-tuning" id="toc-fase-2-ajuste-fino-fine-tuning" class="nav-link" data-scroll-target="#fase-2-ajuste-fino-fine-tuning">Fase 2: Ajuste fino (Fine-tuning)</a></li>
  </ul></li>
  <li><a href="#tipos-de-alucinaciones" id="toc-tipos-de-alucinaciones" class="nav-link" data-scroll-target="#tipos-de-alucinaciones">Tipos de alucinaciones</a></li>
  <li><a href="#estrategias-para-reducir-alucinaciones" id="toc-estrategias-para-reducir-alucinaciones" class="nav-link" data-scroll-target="#estrategias-para-reducir-alucinaciones">Estrategias para reducir alucinaciones</a></li>
  <li><a href="#limitaciones-fundamentales-de-los-llm" id="toc-limitaciones-fundamentales-de-los-llm" class="nav-link" data-scroll-target="#limitaciones-fundamentales-de-los-llm">Limitaciones fundamentales de los LLM</a></li>
  <li><a href="#implicaciones-éticas-para-la-investigación" id="toc-implicaciones-éticas-para-la-investigación" class="nav-link" data-scroll-target="#implicaciones-éticas-para-la-investigación">Implicaciones éticas para la investigación</a>
  <ul class="collapse">
  <li><a href="#autoría-y-atribución" id="toc-autoría-y-atribución" class="nav-link" data-scroll-target="#autoría-y-atribución">Autoría y atribución</a></li>
  <li><a href="#integridad-académica" id="toc-integridad-académica" class="nav-link" data-scroll-target="#integridad-académica">Integridad académica</a></li>
  <li><a href="#transparencia" id="toc-transparencia" class="nav-link" data-scroll-target="#transparencia">Transparencia</a></li>
  </ul></li>
  <li><a href="#glosario" id="toc-glosario" class="nav-link" data-scroll-target="#glosario">Glosario</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Fundamentos</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Este capítulo presenta los conceptos esenciales para usar IA generativa de forma responsable en investigación. La primera sección contiene las <strong>tres ideas fuerza</strong> que se presentan en el taller. El resto es material de profundización para leer después.</p>
<section id="tres-ideas-fuerza" class="level2">
<h2 class="anchored" data-anchor-id="tres-ideas-fuerza">Tres ideas fuerza</h2>
<section id="un-llm-predice-la-siguiente-palabra" class="level3">
<h3 class="anchored" data-anchor-id="un-llm-predice-la-siguiente-palabra">Un LLM predice la siguiente palabra</h3>
<section id="ia-generativa-más-que-texto" class="level4">
<h4 class="anchored" data-anchor-id="ia-generativa-más-que-texto">IA generativa: más que texto</h4>
<p>Cuando hablamos de “inteligencia artificial generativa”, nos referimos a modelos capaces de crear contenido nuevo. Existen distintos tipos según lo que generan:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 47%">
<col style="width: 29%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Tipo de modelo</th>
<th>Ejemplos</th>
<th>Genera</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Lenguaje (LLM)</strong></td>
<td>ChatGPT, Claude, Gemini</td>
<td>Texto y código</td>
</tr>
<tr class="even">
<td><strong>Imagen</strong></td>
<td>DALL-E, Midjourney, Stable Diffusion</td>
<td>Imágenes a partir de texto</td>
</tr>
<tr class="odd">
<td><strong>Audio</strong></td>
<td>Suno, ElevenLabs</td>
<td>Música, voz sintética</td>
</tr>
<tr class="even">
<td><strong>Video</strong></td>
<td>Sora, Runway, Gemini</td>
<td>Videos a partir de texto</td>
</tr>
<tr class="odd">
<td><strong>Multimodal</strong></td>
<td>GPT-4o, Gemini</td>
<td>Combinan texto, imagen, audio</td>
</tr>
</tbody>
</table>
<p>A la fecha, <strong>los modelos de lenguaje son los más maduros y confiables</strong> para uso profesional. Por eso el taller se centra en ellos — pero es importante saber que el ecosistema es más amplio y evoluciona rápidamente.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Gemini: un caso multimodal
</div>
</div>
<div class="callout-body-container callout-body">
<p>Gemini (Google) aparece en varias filas de la tabla porque es un modelo multimodal: puede procesar y generar texto, imágenes, audio y video. Sin embargo, su uso más extendido sigue siendo la generación de texto, y es la herramienta principal que usaremos en el taller. Google ha ido diferenciando sus modelos especializados — por ejemplo, <a href="https://deepmind.google/models/gemini-image/">Nano Banana</a> es su familia de modelos dedicados a generación de imágenes.</p>
</div>
</div>
</section>
<section id="dos-formas-de-usar-un-modelo" class="level4">
<h4 class="anchored" data-anchor-id="dos-formas-de-usar-un-modelo">Dos formas de usar un modelo</h4>
<p>Un mismo modelo de lenguaje puede usarse de formas muy distintas según la interfaz:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Asistente web</strong></th>
<th><strong>Integración CLI / editor</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Ejemplos</strong></td>
<td>gemini.google.com, chatgpt.com, claude.ai</td>
<td>Gemini CLI, Claude Code, GitHub Copilot</td>
</tr>
<tr class="even">
<td><strong>Interfaz</strong></td>
<td>Chat en el navegador, diseñado para ser fácil de usar</td>
<td>Terminal o editor de código, requiere familiaridad técnica</td>
</tr>
<tr class="odd">
<td><strong>Contexto</strong></td>
<td>Tú copias y pegas el texto que quieres que el modelo vea</td>
<td>El modelo accede directamente a los archivos de tu proyecto</td>
</tr>
<tr class="even">
<td><strong>Ideal para</strong></td>
<td>Consultas puntuales, redacción, exploración</td>
<td>Trabajo sostenido sobre un proyecto completo</td>
</tr>
</tbody>
</table>
<p>Los <strong>asistentes web</strong> son aplicaciones donde el modelo viene envuelto en una interfaz visual orientada al usuario: escribes en un chat y recibes respuestas. Son el punto de entrada más accesible.</p>
<p>Las <strong>herramientas CLI</strong> (línea de comandos) no tienen esa interfaz visual, pero ofrecen una ventaja importante: el modelo puede leer y operar sobre todo el contexto de tu proyecto — archivos, estructura de carpetas, código — sin que tengas que copiar nada manualmente.</p>
<div id="fig-interfaces" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interfaces-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-interfaces" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-gemini-web" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-gemini-web-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/fundamentos/gemini-web.png" class="img-fluid figure-img" data-ref-parent="fig-interfaces">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-gemini-web-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Asistente web (gemini.google.com)
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-interfaces" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-gemini-cli" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-gemini-cli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/fundamentos/gemini-cli.png" class="img-fluid figure-img" data-ref-parent="fig-interfaces">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-gemini-cli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Gemini CLI en la terminal
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interfaces-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.1: Dos formas de usar el mismo modelo: interfaz web conversacional (izquierda) vs.&nbsp;línea de comandos con acceso al contexto del proyecto (derecha).
</figcaption>
</figure>
</div>
<p>En este taller trabajaremos con ambas formas. Cada actividad ofrece un <strong>Camino A</strong> (asistente web) y un <strong>Camino B</strong> (CLI/editor) para que elijas según tu comodidad.</p>
</section>
<section id="la-arquitectura-transformer" class="level4">
<h4 class="anchored" data-anchor-id="la-arquitectura-transformer">La arquitectura transformer</h4>
<p>Todos los LLM actuales se basan en una arquitectura llamada <strong>transformer</strong>, introducida en 2017 por investigadores de Google en el artículo <em>“Attention Is All You Need”</em>. Su innovación clave es el <strong>mecanismo de atención</strong>: en lugar de procesar el texto palabra por palabra en orden, el modelo puede “mirar” todas las palabras de una secuencia simultáneamente y determinar cuáles son relevantes entre sí.</p>
<p>Por ejemplo, en la frase <em>“Fui al banco a sentarme”</em>, el mecanismo de atención conecta “banco” con “sentarme” y deduce que se trata de un asiento, no de una institución financiera. Sin atención, el modelo procesaría “banco” sin considerar el resto de la frase y no podría desambiguar.</p>
<div id="fig-transformer-explainer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-transformer-explainer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/fundamentos/transformer-explainer.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-transformer-explainer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.2: Transformer Explainer: herramienta interactiva que visualiza en tiempo real cómo un transformer procesa texto, mostrando el embedding, los bloques de atención y las probabilidades de la siguiente palabra. Fuente: Polo Club of Data Science, Georgia Tech.
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Demostración en vivo
</div>
</div>
<div class="callout-body-container callout-body">
<p>Durante el taller exploraremos <a href="https://poloclub.github.io/transformer-explainer/">Transformer Explainer</a>, una herramienta interactiva que permite ver en tiempo real cómo un transformer procesa texto y calcula la siguiente palabra. Puedes escribir cualquier frase y observar cómo fluye a través de las capas del modelo.</p>
</div>
</div>
</section>
<section id="de-la-arquitectura-a-la-predicción" class="level4">
<h4 class="anchored" data-anchor-id="de-la-arquitectura-a-la-predicción">De la arquitectura a la predicción</h4>
<p>Un modelo de lenguaje grande (LLM, por <em>Large Language Model</em>) no “sabe” cosas ni “entiende” como un humano. Gracias a la arquitectura transformer, lo que hace es:</p>
<blockquote class="blockquote">
<p><strong>Calcular la probabilidad de qué palabra viene después</strong>, basándose en patrones estadísticos aprendidos de millones de textos.</p>
</blockquote>
<p>Cuando escribes “El cielo es…”, el modelo calcula que “azul” tiene alta probabilidad de ser la siguiente palabra, porque ha visto esa secuencia muchas veces en su entrenamiento. En el Transformer Explainer (<a href="#fig-transformer-explainer" class="quarto-xref">Figura&nbsp;<span>1.2</span></a>) puedes ver exactamente esto: a la derecha aparecen las palabras candidatas con sus probabilidades.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Analogía útil
</div>
</div>
<div class="callout-body-container callout-body">
<p>Imagina un autocompletado muy sofisticado. Cuando tu teléfono sugiere la siguiente palabra en un mensaje, hace algo similar (aunque a menor escala). El LLM hace esto con toda la potencia de miles de millones de parámetros y la capacidad de atención del transformer.</p>
</div>
</div>
<p><strong>Implicación práctica:</strong> El modelo genera texto que <em>parece</em> correcto porque sigue patrones de lenguaje humano, pero no está razonando sobre la verdad de lo que dice.</p>
</section>
</section>
<section id="por-eso-alucina" class="level3">
<h3 class="anchored" data-anchor-id="por-eso-alucina">Por eso alucina</h3>
<p>Las “alucinaciones” son respuestas que parecen plausibles pero son incorrectas o inventadas. Ocurren porque:</p>
<blockquote class="blockquote">
<p><strong>El modelo siempre genera la siguiente palabra más probable</strong>, aunque no tenga información real sobre el tema.</p>
</blockquote>
<p>Si le preguntas por una referencia bibliográfica, el modelo puede generar algo como:</p>
<blockquote class="blockquote">
<p>García, M. &amp; López, J. (2023). Métodos innovadores en ciencias sociales. <em>Revista de Investigación Social</em>, 45(2), 112-128.</p>
</blockquote>
<p>Esta referencia puede no existir. El modelo generó un patrón que <em>parece</em> una cita académica válida porque ha visto miles de citas similares.</p>
<section id="por-qué-las-alucinaciones-son-inevitables" class="level4">
<h4 class="anchored" data-anchor-id="por-qué-las-alucinaciones-son-inevitables">Por qué las alucinaciones son inevitables</h4>
<p>Un artículo de investigación de OpenAI <span class="citation" data-cites="kalai2025hallucinate">(<a href="references.html#ref-kalai2025hallucinate" role="doc-biblioref">Kalai et&nbsp;al. 2025</a>)</span> explica que las alucinaciones no son un defecto que se pueda corregir por completo, sino una consecuencia estructural del entrenamiento:</p>
<ol type="1">
<li><p><strong>El modelo aprende de patrones, no de verdades.</strong> Durante el pre-entrenamiento, el modelo ve millones de textos pero nunca recibe etiquetas de “verdadero” o “falso”. Aprende <em>qué suena correcto</em>, no <em>qué es correcto</em>.</p></li>
<li><p><strong>Algunos hechos no tienen patrón.</strong> Hay información que sigue reglas claras (ortografía, gramática) y el modelo la aprende bien. Pero datos arbitrarios — como la fecha de nacimiento de una persona específica — no siguen ningún patrón predecible, y ahí el modelo necesariamente inventa.</p></li>
<li><p><strong>Las evaluaciones premian adivinar.</strong> Cuando los modelos se evalúan solo por precisión, les conviene más adivinar que decir “no sé”. Un modelo que responde al azar tiene alguna probabilidad de acertar; uno que se abstiene, obtiene cero puntos.</p></li>
</ol>
<p>Dicho de otro modo: las alucinaciones se pueden reducir, pero no eliminar — son parte de la naturaleza estadística de estos modelos. Como una curva que se acerca cada vez más a cero sin llegar a tocarlo.</p>
<div id="fig-asintota" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-asintota-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="assets/fundamentos/asintota-alucinaciones.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-asintota-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.3: A medida que los modelos mejoran, las alucinaciones disminuyen, pero nunca llegan a cero: se comportan como una asíntota.
</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Advertencia</span>Atención
</div>
</div>
<div class="callout-body-container callout-body">
<p>Las alucinaciones son especialmente peligrosas en investigación porque:</p>
<ul>
<li>Están bien redactadas y usan un tono formal que inspira confianza</li>
<li>Siguen el formato esperado (DOI, números de página, etc.)</li>
<li>Son difíciles de detectar sin verificación manual</li>
<li>El modelo <em>no sabe que no sabe</em>: genera con la misma confianza una respuesta correcta y una inventada</li>
</ul>
</div>
</div>
<p><strong>Implicación práctica:</strong> Nunca confíes en referencias, datos o afirmaciones factuales generadas por IA sin verificar en fuentes primarias.</p>
</section>
</section>
<section id="dos-técnicas-para-trabajar-con-ia" class="level3">
<h3 class="anchored" data-anchor-id="dos-técnicas-para-trabajar-con-ia">Dos técnicas para trabajar con IA</h3>
<p>Un LLM responde según cómo le preguntes. Por eso, la forma en que interactúas con el modelo importa tanto como lo que le pides. En el taller usaremos dos técnicas complementarias:</p>
<section id="iterative-prompting-diálogo-iterativo" class="level4">
<h4 class="anchored" data-anchor-id="iterative-prompting-diálogo-iterativo">Iterative prompting (diálogo iterativo)</h4>
<p>Consiste en <strong>conversar con la IA de forma sostenida</strong>: explorar ideas, hacer preguntas, discutir enfoques y profundizar progresivamente. Al final de la conversación, le pides al modelo que <strong>sintetice</strong> lo discutido en un formato útil.</p>
<blockquote class="blockquote">
<p><strong>Conversas con la IA y luego le pides que sintetice.</strong></p>
</blockquote>
<p>Es la forma más natural de interactuar con un LLM. Funciona especialmente bien cuando necesitas explorar un tema, pensar en voz alta o evaluar diferentes opciones antes de tomar una decisión.</p>
<pre class="text"><code>Soy investigador/a en [tu área] y me interesa explorar [tu tema].
Quiero conversar contigo para ir definiendo posibles preguntas
de investigación.</code></pre>
<p>Después de varias rondas de conversación, puedes cerrar con:</p>
<pre class="text"><code>Sintetiza nuestra conversación en: un resumen del tema explorado,
los enfoques que discutimos y 2-3 posibles direcciones de
investigación.</code></pre>
</section>
<section id="meta-prompting" class="level4">
<h4 class="anchored" data-anchor-id="meta-prompting">Meta prompting</h4>
<p>Consiste en <strong>pedirle a la IA que diseñe instrucciones (prompts) especializadas</strong> que usarás después. En vez de conversar, le pides que construya una herramienta reutilizable para una tarea específica.</p>
<blockquote class="blockquote">
<p><strong>Le pides a la IA que diseñe un prompt, y luego usas ese prompt.</strong></p>
</blockquote>
<pre class="text"><code>Diseña un prompt para crear un asistente que me permita definir
de manera correcta mis preguntas de investigación. El asistente
debe guiarme durante todo el proceso y el resultado es tener una
pregunta general y al menos dos específicas.</code></pre>
<p>El modelo te entregará un prompt que puedes copiar y usar en una nueva conversación, o guardar para reutilizarlo en el futuro.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>¿Cuándo usar cada una?
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Iterative prompting</strong> cuando necesitas <em>explorar</em>: no tienes claro el enfoque, quieres discutir opciones o estás en una etapa temprana de la investigación.</li>
<li><strong>Meta prompting</strong> cuando necesitas <em>producir</em>: ya sabes qué quieres lograr y necesitas un prompt bien diseñado para obtener un resultado estructurado.</li>
<li>En la práctica, se combinan: primero exploras con iterative prompting y luego diseñas prompts especializados con meta prompting.</li>
</ul>
</div>
</div>
<p><strong>Implicación práctica:</strong> No te limites a escribir un prompt directo. Conversa con la IA para explorar tu tema y pídele que diseñe instrucciones especializadas para las tareas que necesitas realizar.</p>
<hr>
</section>
</section>
</section>
<section id="profundización-teórica" class="level2">
<h2 class="anchored" data-anchor-id="profundización-teórica">Profundización teórica</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Lectura posterior
</div>
</div>
<div class="callout-body-container callout-body">
<p>Esta sección expande los conceptos anteriores para quienes deseen entender mejor el funcionamiento de los LLM. No es necesaria para las actividades del taller.</p>
</div>
</div>
<section id="cómo-aprenden-los-llm" class="level3">
<h3 class="anchored" data-anchor-id="cómo-aprenden-los-llm">Cómo aprenden los LLM</h3>
<p>Los modelos de lenguaje actuales se entrenan en dos fases principales:</p>
<section id="fase-1-pre-entrenamiento" class="level4">
<h4 class="anchored" data-anchor-id="fase-1-pre-entrenamiento">Fase 1: Pre-entrenamiento</h4>
<p>El modelo procesa cantidades masivas de texto (libros, artículos, páginas web) y aprende a predecir qué palabra viene después en una secuencia. Este proceso ajusta miles de millones de parámetros (pesos numéricos) que capturan patrones estadísticos del lenguaje.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Aspecto</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Datos</strong></td>
<td>Cientos de miles de millones de palabras</td>
</tr>
<tr class="even">
<td><strong>Tarea</strong></td>
<td>Predecir la siguiente palabra (o token)</td>
</tr>
<tr class="odd">
<td><strong>Resultado</strong></td>
<td>Modelo base con conocimiento general</td>
</tr>
</tbody>
</table>
</section>
<section id="fase-2-ajuste-fino-fine-tuning" class="level4">
<h4 class="anchored" data-anchor-id="fase-2-ajuste-fino-fine-tuning">Fase 2: Ajuste fino (Fine-tuning)</h4>
<p>El modelo base se ajusta con ejemplos específicos para seguir instrucciones, responder preguntas y mantener conversaciones. Técnicas como RLHF (<em>Reinforcement Learning from Human Feedback</em>) alinean las respuestas con preferencias humanas.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Aspecto</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Datos</strong></td>
<td>Conversaciones y preferencias humanas</td>
</tr>
<tr class="even">
<td><strong>Tarea</strong></td>
<td>Generar respuestas útiles y seguras</td>
</tr>
<tr class="odd">
<td><strong>Resultado</strong></td>
<td>Modelo asistente (ChatGPT, Claude, etc.)</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="tipos-de-alucinaciones" class="level3">
<h3 class="anchored" data-anchor-id="tipos-de-alucinaciones">Tipos de alucinaciones</h3>
<p>Las alucinaciones pueden clasificarse según su naturaleza:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 46%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th>Tipo</th>
<th>Descripción</th>
<th>Ejemplo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Fabricación</strong></td>
<td>Inventar información inexistente</td>
<td>Citas bibliográficas falsas</td>
</tr>
<tr class="even">
<td><strong>Contradicción</strong></td>
<td>Afirmar algo opuesto a hechos conocidos</td>
<td>“Einstein nació en Francia”</td>
</tr>
<tr class="odd">
<td><strong>Inconsistencia</strong></td>
<td>Contradecirse en la misma respuesta</td>
<td>Dar dos fechas diferentes para el mismo evento</td>
</tr>
<tr class="even">
<td><strong>Extrapolación</strong></td>
<td>Generalizar incorrectamente</td>
<td>“Todos los estudios muestran que…” cuando solo hay algunos</td>
</tr>
</tbody>
</table>
</section>
<section id="estrategias-para-reducir-alucinaciones" class="level3">
<h3 class="anchored" data-anchor-id="estrategias-para-reducir-alucinaciones">Estrategias para reducir alucinaciones</h3>
<p>Aunque no puedes eliminar las alucinaciones completamente, puedes reducirlas:</p>
<ol type="1">
<li><strong>Proporcionar contexto</strong>: Incluye información relevante en tu prompt</li>
<li><strong>Pedir fuentes</strong>: Solicita que cite de dónde proviene la información</li>
<li><strong>Verificar siempre</strong>: Contrasta afirmaciones con fuentes primarias</li>
<li><strong>Usar herramientas especializadas</strong>: Elicit y SciSpace trabajan directamente con papers reales</li>
<li><strong>Limitar el alcance</strong>: Preguntas específicas generan menos alucinaciones que preguntas amplias</li>
</ol>
</section>
<section id="limitaciones-fundamentales-de-los-llm" class="level3">
<h3 class="anchored" data-anchor-id="limitaciones-fundamentales-de-los-llm">Limitaciones fundamentales de los LLM</h3>
<p>Es importante entender qué <strong>no pueden</strong> hacer los LLM actuales:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 48%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="header">
<th>Limitación</th>
<th>Explicación</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>No acceden a internet en tiempo real</strong></td>
<td>Solo conocen información de su entrenamiento (salvo que tengan búsqueda web integrada)</td>
</tr>
<tr class="even">
<td><strong>No recuerdan conversaciones previas</strong></td>
<td>Cada sesión comienza sin memoria (salvo sistemas con memoria explícita)</td>
</tr>
<tr class="odd">
<td><strong>No razonan como humanos</strong></td>
<td>Simulan razonamiento mediante patrones, no comprensión real</td>
</tr>
<tr class="even">
<td><strong>No tienen intenciones</strong></td>
<td>No “quieren” nada; solo generan la siguiente secuencia probable</td>
</tr>
<tr class="odd">
<td><strong>No pueden verificar hechos</strong></td>
<td>Generan texto plausible, no necesariamente verdadero</td>
</tr>
</tbody>
</table>
</section>
<section id="implicaciones-éticas-para-la-investigación" class="level3">
<h3 class="anchored" data-anchor-id="implicaciones-éticas-para-la-investigación">Implicaciones éticas para la investigación</h3>
<p>El uso de IA en investigación académica plantea consideraciones éticas específicas:</p>
<section id="autoría-y-atribución" class="level4">
<h4 class="anchored" data-anchor-id="autoría-y-atribución">Autoría y atribución</h4>
<ul>
<li>La IA no puede ser autora porque no asume responsabilidad</li>
<li>El investigador es responsable de todo el contenido, incluyendo errores de la IA</li>
<li>Debe declararse explícitamente el uso de herramientas de IA</li>
</ul>
</section>
<section id="integridad-académica" class="level4">
<h4 class="anchored" data-anchor-id="integridad-académica">Integridad académica</h4>
<ul>
<li>El contenido generado por IA debe verificarse rigurosamente</li>
<li>No debe usarse IA para fabricar datos o resultados</li>
<li>Las imágenes científicas no deben ser generadas ni manipuladas con IA</li>
</ul>
</section>
<section id="transparencia" class="level4">
<h4 class="anchored" data-anchor-id="transparencia">Transparencia</h4>
<ul>
<li>Los métodos deben ser reproducibles</li>
<li>El uso de IA en cualquier etapa debe documentarse</li>
<li>Los lectores deben poder evaluar el rol de la IA en el trabajo</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Importante</span>Recuerda
</div>
</div>
<div class="callout-body-container callout-body">
<p>Las políticas editoriales de Taylor &amp; Francis, Elsevier y Springer Nature coinciden en estos principios. Consulta el capítulo <a href="./recursos.html">Recursos</a> para ver las políticas específicas.</p>
</div>
</div>
</section>
</section>
<section id="glosario" class="level3">
<h3 class="anchored" data-anchor-id="glosario">Glosario</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 42%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="header">
<th>Término</th>
<th>Definición</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>LLM</strong></td>
<td><em>Large Language Model</em>. Modelo de lenguaje entrenado con grandes cantidades de texto, basado en la arquitectura transformer.</td>
</tr>
<tr class="even">
<td><strong>Transformer</strong></td>
<td>Arquitectura de red neuronal introducida en 2017. Su mecanismo de atención permite procesar todas las palabras de una secuencia simultáneamente.</td>
</tr>
<tr class="odd">
<td><strong>Atención</strong></td>
<td>Mecanismo que permite al modelo determinar qué palabras de la entrada son relevantes entre sí para generar la siguiente palabra.</td>
</tr>
<tr class="even">
<td><strong>Token</strong></td>
<td>Unidad mínima de texto que procesa el modelo (puede ser una palabra, parte de palabra o símbolo).</td>
</tr>
<tr class="odd">
<td><strong>Prompt</strong></td>
<td>Instrucción o texto de entrada que se le da al modelo.</td>
</tr>
<tr class="even">
<td><strong>Alucinación</strong></td>
<td>Respuesta generada que parece plausible pero es incorrecta o inventada.</td>
</tr>
<tr class="odd">
<td><strong>Iterative prompting</strong></td>
<td>Técnica de conversar con la IA de forma sostenida, explorando y profundizando, para luego pedir una síntesis de lo discutido.</td>
</tr>
<tr class="even">
<td><strong>Meta prompting</strong></td>
<td>Técnica de pedirle a la IA que diseñe instrucciones (prompts) especializadas para usarlas después.</td>
</tr>
<tr class="odd">
<td><strong>Fine-tuning</strong></td>
<td>Ajuste del modelo con datos específicos para una tarea particular.</td>
</tr>
<tr class="even">
<td><strong>RLHF</strong></td>
<td><em>Reinforcement Learning from Human Feedback</em>. Técnica para alinear modelos con preferencias humanas.</td>
</tr>
<tr class="odd">
<td><strong>Contexto</strong></td>
<td>Información adicional incluida en el prompt para guiar la respuesta.</td>
</tr>
</tbody>
</table>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-kalai2025hallucinate" class="csl-entry" role="listitem">
Kalai, Adam Tauman, Ofir Nachum, Santosh S. Vempala, y Edwin Zhang. 2025. <span>«Why Language Models Hallucinate»</span>. <a href="https://openai.com/index/why-language-models-hallucinate/">https://openai.com/index/why-language-models-hallucinate/</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script>
// Add copy button to all pre elements that don't have one
document.addEventListener('DOMContentLoaded', function() {
  document.querySelectorAll('pre.text').forEach(function(pre) {
    // Create button container
    const container = document.createElement('div');
    container.className = 'code-copy-container';
    container.style.position = 'relative';

    // Wrap pre in container
    pre.parentNode.insertBefore(container, pre);
    container.appendChild(pre);

    // Create copy button
    const button = document.createElement('button');
    button.className = 'code-copy-button';
    button.setAttribute('title', 'Copiar');
    button.innerHTML = '<i class="bi bi-clipboard"></i>';
    button.style.cssText = 'position: absolute; top: 0.5rem; right: 0.5rem; padding: 0.25rem 0.5rem; border: none; background: #f8f9fa; border-radius: 4px; cursor: pointer; opacity: 0; transition: opacity 0.2s;';

    container.appendChild(button);

    // Show button on hover
    container.addEventListener('mouseenter', function() {
      button.style.opacity = '1';
    });
    container.addEventListener('mouseleave', function() {
      button.style.opacity = '0';
    });

    // Copy functionality
    button.addEventListener('click', function() {
      const code = pre.querySelector('code') ? pre.querySelector('code').textContent : pre.textContent;
      navigator.clipboard.writeText(code).then(function() {
        button.innerHTML = '<i class="bi bi-check"></i>';
        setTimeout(function() {
          button.innerHTML = '<i class="bi bi-clipboard"></i>';
        }, 2000);
      });
    });
  });
});
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Bienvenida">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Bienvenida</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./modulo-1.html" class="pagination-link" aria-label="Módulo 1">
        <span class="nav-page-text"><span class="chapter-title">Módulo 1</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>